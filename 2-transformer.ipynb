{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GAQQqIIetaU",
        "outputId": "5b2aa826-7028-43fa-bff7-71dead25aee7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import math\n",
        "import copy"
      ],
      "metadata": {
        "id": "xT58eU0SYT8R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/drive/MyDrive/NLP/v2/en-hi'\n",
        "\n",
        "# Define the file names\n",
        "en_file_name = 'train.en'\n",
        "hi_file_name = 'train.hi'\n",
        "\n",
        "# Define the paths to the files\n",
        "en_file_path = os.path.join(directory_path, en_file_name)\n",
        "hi_file_path = os.path.join(directory_path, hi_file_name)"
      ],
      "metadata": {
        "id": "ERjt6_W0d6AQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read English sentences from train.en\n",
        "with open(en_file_path, 'r', encoding='utf-8') as en_file:\n",
        "    en_sentences = [line.strip() for line in en_file.readlines()]\n",
        "\n",
        "# Read Hindi sentences from train.hi\n",
        "with open(hi_file_path, 'r', encoding='utf-8') as hi_file:\n",
        "    hi_sentences = [line.strip() for line in hi_file.readlines()]\n",
        "\n",
        "# Print the first few sentences as a sample\n",
        "print(\"Sample English Sentences:\")\n",
        "print(en_sentences[:3])\n",
        "\n",
        "print(\"\\nSample Hindi Sentences:\")\n",
        "print(hi_sentences[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj-pgokMd65K",
        "outputId": "950fbfc8-cb9f-43f7-b08f-42ae14413eb9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample English Sentences:\n",
            "[\"However, Paes, who was partnering Australia's Paul Hanley, could only go as far as the quarterfinals where they lost to Bhupathi and Knowles\", 'Whosoever desires the reward of the world, with Allah is the reward of the world and of the Everlasting Life. Allah is the Hearer, the Seer.', 'The value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness.']\n",
            "\n",
            "Sample Hindi Sentences:\n",
            "['आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।', 'और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है', 'जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_sentences = en_sentences[:50]\n",
        "hi_sentences = hi_sentences[:50]"
      ],
      "metadata": {
        "id": "cPfJnhCB_hbt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        # Initialize dimensions\n",
        "        self.d_model = d_model # Model's dimension\n",
        "        self.num_heads = num_heads # Number of attention heads\n",
        "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
        "\n",
        "        # Linear layers for transforming inputs\n",
        "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
        "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
        "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
        "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        # Calculate attention scores\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Softmax is applied to obtain attention probabilities\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Multiply by values to obtain the final output\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Reshape the input to have num_heads for multi-head attention\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine the multiple heads back to original shape\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        # Apply linear transformations and split heads\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        # Perform scaled dot-product attention\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Combine heads and apply output transformation\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output"
      ],
      "metadata": {
        "id": "KOFyXtmqYdHs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ],
      "metadata": {
        "id": "WiRKXlAHYjGV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ],
      "metadata": {
        "id": "eLWe_0heYyN5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder and Decoder blocks"
      ],
      "metadata": {
        "id": "iO6wrX6jY8X6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "-jDFBkLvY1OI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x"
      ],
      "metadata": {
        "id": "hflukFIsY_jl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer Model"
      ],
      "metadata": {
        "id": "mzhT7QgZZqdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # Convert tgt to a long tensor and then to float\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2).float()\n",
        "\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "\n",
        "        # Use broadcasting to apply the mask\n",
        "        tgt_mask = tgt_mask * nopeak_mask[None, :, :]\n",
        "\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "\n",
        "        # Apply softmax to the output\n",
        "        output = F.softmax(self.fc(dec_output), dim=-1)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "h7_YWOjxZEFh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and Preprocess data"
      ],
      "metadata": {
        "id": "McD9oYImZxBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def tokenize_sentences(sentences, vocab, max_length):\n",
        "    tokenized = []\n",
        "    for sentence in sentences:\n",
        "        tokens = [vocab[word] if word in vocab else vocab[\"<UNK>\"] for word in sentence.split()]\n",
        "        tokens += [vocab[\"<PAD>\"]] * (max_length - len(tokens))  # Pad to the maximum length\n",
        "        tokenized.append(tokens)\n",
        "    return tokenized\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    vocab = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}  # Special tokens for padding, start of sequence, end of sequence, and unknown words\n",
        "    idx = len(vocab)\n",
        "\n",
        "    for sentence in sentences:\n",
        "        for word in sentence.split():\n",
        "            if word not in vocab:\n",
        "                vocab[word] = idx\n",
        "                idx += 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "def preprocess_and_split_data(en_sentences, hi_sentences, test_size=0.2, random_state=42):\n",
        "    # Build vocabularies\n",
        "    en_vocab = build_vocab(en_sentences)\n",
        "    hi_vocab = build_vocab(hi_sentences)\n",
        "\n",
        "    # Find maximum sequence lengths\n",
        "    en_max_length = max(len(sentence.split()) for sentence in en_sentences)\n",
        "    hi_max_length = max(len(sentence.split()) for sentence in hi_sentences)\n",
        "\n",
        "    # Tokenize and pad sentences\n",
        "    en_tokenized = tokenize_sentences(en_sentences, en_vocab, 200)\n",
        "    hi_tokenized = tokenize_sentences(hi_sentences, hi_vocab, 200)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    src_data = torch.tensor(en_tokenized)\n",
        "    tgt_data = torch.tensor(hi_tokenized)\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    src_train, src_test, tgt_train, tgt_test = train_test_split(src_data, tgt_data, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    return src_train, src_test, tgt_train, tgt_test, en_vocab, hi_vocab\n",
        "\n",
        "\n",
        "src_train, src_test, tgt_train, tgt_test, en_vocab, hi_vocab = preprocess_and_split_data(en_sentences, hi_sentences)\n",
        "\n",
        "# Print the train and test sets along with vocabularies\n",
        "# print(\"Train Data:\")\n",
        "# for en, hi in zip(src_train, tgt_train):\n",
        "#     print(f\"English: {en}, Hindi: {hi}\")\n",
        "\n",
        "# print(\"\\nTest Data:\")\n",
        "# for en, hi in zip(src_test, tgt_test):\n",
        "#     print(f\"English: {en}, Hindi: {hi}\")\n",
        "\n",
        "# print(\"\\nEnglish Vocabulary:\")\n",
        "# print(en_vocab)\n",
        "\n",
        "# print(\"\\nHindi Vocabulary:\")\n",
        "# print(hi_vocab)\n"
      ],
      "metadata": {
        "id": "dV5BZQ6PdZvi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "f6OdXTK8UCad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model and training parameters\n",
        "src_vocab_size = len(en_vocab)\n",
        "tgt_vocab_size = len(hi_vocab)\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "max_seq_length = 200\n",
        "dropout = 0.1\n",
        "\n",
        "# Initialize your Transformer model\n",
        "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Training loop\n",
        "transformer.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    output = transformer(src_train, tgt_train[:, :-1])\n",
        "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_train[:, 1:].contiguous().view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEE6nB39emtq",
        "outputId": "2a1144e8-ea3d-48f2-c5a1-304591230afa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 6.304398059844971\n",
            "Epoch: 2, Loss: 6.300017833709717\n",
            "Epoch: 3, Loss: 6.27338981628418\n",
            "Epoch: 4, Loss: 6.25996732711792\n",
            "Epoch: 5, Loss: 6.259002208709717\n",
            "Epoch: 6, Loss: 6.258815765380859\n",
            "Epoch: 7, Loss: 6.258754253387451\n",
            "Epoch: 8, Loss: 6.258720874786377\n",
            "Epoch: 9, Loss: 6.258698463439941\n",
            "Epoch: 10, Loss: 6.258686542510986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "6gqmyX4EUFFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_to_sentence(tensor, vocab, remove_pad=True):\n",
        "    sentence = []\n",
        "    for num in tensor:\n",
        "      word = list(vocab.keys())[list(vocab.values()).index(num.item())]\n",
        "      sentence.append(word)\n",
        "\n",
        "    if remove_pad:\n",
        "          sentence = [word for word in sentence if word != '<PAD>']\n",
        "\n",
        "    return \" \".join(sentence)"
      ],
      "metadata": {
        "id": "4BeteiWoW9sb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    val_output = transformer(src_test, tgt_test[:, :-1])\n",
        "\n",
        "    # Print input and predicted tensors\n",
        "    # print(\"Input Tensor:\")\n",
        "    # print(src_test)\n",
        "\n",
        "    # print(\"\\nPredicted Tensor:\")\n",
        "    # predicted_tensor = val_output.argmax(dim=-1)\n",
        "    # print(predicted_tensor)\n",
        "\n",
        "    # Calculate and print validation loss\n",
        "    val_loss = criterion(val_output.contiguous().view(-1, tgt_vocab_size), tgt_test[:, 1:].contiguous().view(-1))\n",
        "    print(f\"Validation Loss: {val_loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0SFqynDUN3z",
        "outputId": "8e03bc06-35ea-4a5a-c98e-fdf9df5321b5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.256841659545898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example output"
      ],
      "metadata": {
        "id": "23azJb-qXDg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_tensor = src_test[0]\n",
        "input_sentence = tensor_to_sentence(input_tensor, en_vocab)\n",
        "print(\"Input: \", input_sentence)\n",
        "\n",
        "\n",
        "target_tensor = tgt_test[0]\n",
        "target_sentence = tensor_to_sentence(target_tensor, hi_vocab)\n",
        "print(\"Expected: \", target_sentence)\n",
        "\n",
        "\n",
        "predicted_tensor = val_output.argmax(dim=-1)\n",
        "predicted_sentence = tensor_to_sentence(predicted_tensor[0], hi_vocab)\n",
        "print(\"Predicted: \", target_sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPjvuT9TXAzq",
        "outputId": "54cc935b-44e5-45ed-f601-43aed4ef5cf4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  Meanwhile, three people came there on a bike.\n",
            "Expected:  इसी बीच एक बाइक पर तीन लोग आते दिखाई दिए।\n",
            "Predicted:  इसी बीच एक बाइक पर तीन लोग आते दिखाई दिए।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ZflpXhmaA5G"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}