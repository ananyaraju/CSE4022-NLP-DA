{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PROBLEM STATEMENT**\n",
        "\n",
        "To build a transformer based translation model for English to Hindi translations as per IIT-M Samanantar Dataset"
      ],
      "metadata": {
        "id": "OtIQgknskGf5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATASET DETAILS**\n",
        "\n",
        "**Link:** https://www.kaggle.com/datasets/mathurinache/samanantar or https://ai4bharat.iitm.ac.in/samanantar/\n",
        "\n",
        "Samanantar is the largest publicly available parallel corpora collection for Indic languages like Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu.\n",
        "\n",
        "The corpus has 49.6M sentence pairs between English to Indian Languages."
      ],
      "metadata": {
        "id": "b2n-WvehlsvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries and Mount Google Drive"
      ],
      "metadata": {
        "id": "uZ85N-SWlZ8C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GAQQqIIetaU",
        "outputId": "6c9242db-4e10-47f5-e6fe-fdfefabc7bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT58eU0SYT8R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "import zipfile\n",
        "import os\n",
        "import math\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and Extract Dataset"
      ],
      "metadata": {
        "id": "Za_4qYgHkQTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k63R2dr5N5ec",
        "outputId": "e5a40fac-d92c-451a-e0fd-78db56222e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/NLP\n",
            "v2  v3.zip\n",
            "File Name                                             Modified             Size\n",
            "v2/                                            2021-05-15 14:00:48            0\n",
            "v2/en-kn/                                      2021-05-15 13:53:38            0\n",
            "v2/en-kn/train.kn                              2021-05-15 14:10:04    625597778\n",
            "v2/en-kn/train.en                              2021-05-15 14:10:02    225137231\n",
            "v2/en-bn/                                      2021-05-15 13:50:00            0\n",
            "v2/en-bn/train.en                              2021-05-15 14:04:26    590453659\n",
            "v2/en-bn/train.bn                              2021-05-15 14:04:32   1494025234\n",
            "v2/en-as/                                      2021-05-15 13:49:58            0\n",
            "v2/en-as/train.as                              2021-05-15 14:02:34     23243174\n",
            "v2/en-as/train.en                              2021-05-15 14:02:34     10327928\n",
            "v2/en-ta/                                      2021-05-15 13:55:40            0\n",
            "v2/en-ta/train.ta                              2021-05-15 14:15:02   1090605836\n",
            "v2/en-ta/train.en                              2021-05-15 14:14:58    354079394\n",
            "v2/en-or/                                      2021-05-15 13:55:12            0\n",
            "v2/en-or/train.or                              2021-05-15 14:12:50    183312208\n",
            "v2/en-or/train.en                              2021-05-15 14:12:48     68411532\n",
            "v2/en-mr/                                      2021-05-15 13:54:50            0\n",
            "v2/en-mr/train.mr                              2021-05-15 14:12:34    636142032\n",
            "v2/en-mr/train.en                              2021-05-15 14:12:30    242539039\n",
            "v2/en-te/                                      2021-05-15 14:24:16            0\n",
            "v2/en-te/train.te                              2021-05-15 14:16:28    773618108\n",
            "v2/en-te/en-kn/                                2021-05-15 14:23:58            0\n",
            "v2/en-te/en-kn/train.kn                        2021-05-15 14:24:00    625597778\n",
            "v2/en-te/en-kn/train.en                        2021-05-15 14:23:58    225137231\n",
            "v2/en-te/en-bn/                                2021-05-15 14:23:32            0\n",
            "v2/en-te/en-bn/train.en                        2021-05-15 14:23:32    590453659\n",
            "v2/en-te/en-bn/train.bn                        2021-05-15 14:23:38   1494025234\n",
            "v2/en-te/en-as/                                2021-05-15 14:23:32            0\n",
            "v2/en-te/en-as/train.as                        2021-05-15 14:23:32     23243174\n",
            "v2/en-te/en-as/train.en                        2021-05-15 14:23:32     10327928\n",
            "v2/en-te/en-ta/                                2021-05-15 14:24:18            0\n",
            "v2/en-te/en-ta/train.ta                        2021-05-15 14:24:24   1090605836\n",
            "v2/en-te/en-ta/train.en                        2021-05-15 14:24:18    354079394\n",
            "v2/en-te/en-or/                                2021-05-15 14:24:12            0\n",
            "v2/en-te/en-or/train.or                        2021-05-15 14:24:12    183312208\n",
            "v2/en-te/en-or/train.en                        2021-05-15 14:24:12     68411532\n",
            "v2/en-te/en-mr/                                2021-05-15 14:24:08            0\n",
            "v2/en-te/en-mr/train.mr                        2021-05-15 14:24:12    636142032\n",
            "v2/en-te/en-mr/train.en                        2021-05-15 14:24:08    242539039\n",
            "v2/en-te/en-hi/                                2021-05-15 14:23:42            0\n",
            "v2/en-te/en-hi/train.hi                        2021-05-15 14:23:56   2455522801\n",
            "v2/en-te/en-hi/train.en                        2021-05-15 14:23:42   1000847966\n",
            "v2/en-te/en-pa/                                2021-05-15 14:24:14            0\n",
            "v2/en-te/en-pa/train.pa                        2021-05-15 14:24:16    587074653\n",
            "v2/en-te/en-pa/train.en                        2021-05-15 14:24:14    247344632\n",
            "v2/en-te/en-gu/                                2021-05-15 14:23:38            0\n",
            "v2/en-te/en-gu/train.gu                        2021-05-15 14:23:40    448906549\n",
            "v2/en-te/en-gu/train.en                        2021-05-15 14:23:38    186363556\n",
            "v2/en-te/en-ml/                                2021-05-15 14:24:02            0\n",
            "v2/en-te/en-ml/train.ml                        2021-05-15 14:24:08   1107061019\n",
            "v2/en-te/en-ml/train.en                        2021-05-15 14:24:02    355007935\n",
            "v2/en-te/train.en                              2021-05-15 14:16:24    278780585\n",
            "v2/en-hi/                                      2021-05-15 13:51:42            0\n",
            "v2/en-hi/train.hi                              2021-05-15 14:09:06   2455522801\n",
            "v2/en-hi/train.en                              2021-05-15 14:08:56   1000847966\n",
            "v2/en-pa/                                      2021-05-15 13:55:18            0\n",
            "v2/en-pa/train.pa                              2021-05-15 14:13:38    587074653\n",
            "v2/en-pa/train.en                              2021-05-15 14:13:34    247344632\n",
            "v2/en-gu/                                      2021-05-15 13:51:20            0\n",
            "v2/en-gu/train.gu                              2021-05-15 14:05:16    448906549\n",
            "v2/en-gu/train.en                              2021-05-15 14:05:10    186363556\n",
            "v2/en-ml/                                      2021-05-15 13:54:06            0\n",
            "v2/en-ml/train.ml                              2021-05-15 14:11:36   1107061019\n",
            "v2/en-ml/train.en                              2021-05-15 14:11:32    355007935\n",
            "Contents of the extracted directory:\n",
            "['v3.zip', 'v2']\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/NLP\n",
        "\n",
        "!ls\n",
        "\n",
        "zip_file_name = 'v3.zip'\n",
        "\n",
        "extract_path = '/content/drive/MyDrive/NLP'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.printdir()\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Contents of the extracted directory:\")\n",
        "print(extracted_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERjt6_W0d6AQ"
      },
      "outputs": [],
      "source": [
        "directory_path = '/content/drive/MyDrive/NLP/v2/en-hi'\n",
        "\n",
        "en_file_name = 'train.en'\n",
        "hi_file_name = 'train.hi'\n",
        "\n",
        "en_file_path = os.path.join(directory_path, en_file_name)\n",
        "hi_file_path = os.path.join(directory_path, hi_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj-pgokMd65K",
        "outputId": "a0dcd952-30b7-42b3-e4db-0ece5a2bc2f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample English Sentences:\n",
            "[\"However, Paes, who was partnering Australia's Paul Hanley, could only go as far as the quarterfinals where they lost to Bhupathi and Knowles\", 'Whosoever desires the reward of the world, with Allah is the reward of the world and of the Everlasting Life. Allah is the Hearer, the Seer.', 'The value of insects in the biosphere is enormous because they outnumber all other living groups in measure of species richness.']\n",
            "\n",
            "Sample Hindi Sentences:\n",
            "['आस्ट्रेलिया के पाल हेनली के साथ जोड़ी बनाने वाले पेस मियामी में क्वार्टरफाइनल तक ही पहुंच सके क्योंकि इस दौर में उन्हें भूपति और नोल्स ने हराया था।', 'और जो शख्स (अपने आमाल का) बदला दुनिया ही में चाहता है तो ख़ुदा के पास दुनिया व आख़िरत दोनों का अज्र मौजूद है और ख़ुदा तो हर शख्स की सुनता और सबको देखता है', 'जैव-मंडल में कीड़ों का मूल्य बहुत है, क्योंकि प्रजातियों की समृद्धि के मामले में उनकी संख्या अन्य जीव समूहों से ज़्यादा है।']\n"
          ]
        }
      ],
      "source": [
        "# Read English sentences from train.en\n",
        "with open(en_file_path, 'r', encoding='utf-8') as en_file:\n",
        "    en_sentences = [line.strip() for line in en_file.readlines()]\n",
        "\n",
        "# Read Hindi sentences from train.hi\n",
        "with open(hi_file_path, 'r', encoding='utf-8') as hi_file:\n",
        "    hi_sentences = [line.strip() for line in hi_file.readlines()]\n",
        "\n",
        "# Print the first few sentences as a sample\n",
        "print(\"Sample English Sentences:\")\n",
        "print(en_sentences[:5])\n",
        "print(\"\\nSample Hindi Sentences:\")\n",
        "print(hi_sentences[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "cPfJnhCB_hbt"
      },
      "outputs": [],
      "source": [
        "en_sentences = en_sentences[:100]\n",
        "hi_sentences = hi_sentences[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOFyXtmqYdHs"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "\n",
        "        # Initialize dimensions\n",
        "        self.d_model = d_model # Model's dimension\n",
        "        self.num_heads = num_heads # Number of attention heads\n",
        "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
        "\n",
        "        # Linear layers for transforming inputs\n",
        "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
        "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
        "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
        "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
        "        # Calculate attention scores\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
        "        if mask is not None:\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "        # Softmax is applied to obtain attention probabilities\n",
        "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        # Multiply by values to obtain the final output\n",
        "        output = torch.matmul(attn_probs, V)\n",
        "        return output\n",
        "\n",
        "    def split_heads(self, x):\n",
        "        # Reshape the input to have num_heads for multi-head attention\n",
        "        batch_size, seq_length, d_model = x.size()\n",
        "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        # Combine the multiple heads back to original shape\n",
        "        batch_size, _, seq_length, d_k = x.size()\n",
        "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
        "\n",
        "    def forward(self, Q, K, V, mask=None):\n",
        "        # Apply linear transformations and split heads\n",
        "        Q = self.split_heads(self.W_q(Q))\n",
        "        K = self.split_heads(self.W_k(K))\n",
        "        V = self.split_heads(self.W_v(V))\n",
        "\n",
        "        # Perform scaled dot-product attention\n",
        "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
        "\n",
        "        # Combine heads and apply output transformation\n",
        "        output = self.W_o(self.combine_heads(attn_output))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WiRKXlAHYjGV"
      },
      "outputs": [],
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PositionWiseFeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eLWe_0heYyN5"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO6wrX6jY8X6"
      },
      "source": [
        "# Encoder and Decoder Blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-jDFBkLvY1OI"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output = self.self_attn(x, x, x, mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm2(x + self.dropout(ff_output))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hflukFIsY_jl"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
        "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + self.dropout(attn_output))\n",
        "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
        "        x = self.norm2(x + self.dropout(attn_output))\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.norm3(x + self.dropout(ff_output))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzhT7QgZZqdU"
      },
      "source": [
        "# Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "h7_YWOjxZEFh"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
        "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def generate_mask(self, src, tgt):\n",
        "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
        "        # Convert tgt to a long tensor and then to float\n",
        "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2).float()\n",
        "        seq_length = tgt.size(1)\n",
        "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
        "        # Use broadcasting to apply the mask\n",
        "        tgt_mask = tgt_mask * nopeak_mask[None, :, :]\n",
        "        return src_mask, tgt_mask\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
        "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
        "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
        "        enc_output = src_embedded\n",
        "        for enc_layer in self.encoder_layers:\n",
        "            enc_output = enc_layer(enc_output, src_mask)\n",
        "        dec_output = tgt_embedded\n",
        "        for dec_layer in self.decoder_layers:\n",
        "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
        "        output = F.softmax(self.fc(dec_output), dim=-1)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McD9oYImZxBw"
      },
      "source": [
        "# Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dV5BZQ6PdZvi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def tokenize_sentences(sentences, vocab, max_length):\n",
        "    tokenized = []\n",
        "    for sentence in sentences:\n",
        "        tokens = [vocab[word] if word in vocab else vocab[\"<UNK>\"] for word in sentence.split()]\n",
        "        tokens += [vocab[\"<PAD>\"]] * (max_length - len(tokens))  # Pad to the maximum length\n",
        "        tokenized.append(tokens)\n",
        "    return tokenized\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    vocab = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}  # Special tokens for padding, start of sequence, end of sequence, and unknown words\n",
        "    idx = len(vocab)\n",
        "    for sentence in sentences:\n",
        "        for word in sentence.split():\n",
        "            if word not in vocab:\n",
        "                vocab[word] = idx\n",
        "                idx += 1\n",
        "    return vocab\n",
        "\n",
        "def preprocess_and_split_data(en_sentences, hi_sentences, test_size=0.2, random_state=42):\n",
        "\n",
        "    # Build vocabularies\n",
        "    en_vocab = build_vocab(en_sentences)\n",
        "    hi_vocab = build_vocab(hi_sentences)\n",
        "\n",
        "    # Find maximum sequence lengths\n",
        "    en_max_length = max(len(sentence.split()) for sentence in en_sentences)\n",
        "    hi_max_length = max(len(sentence.split()) for sentence in hi_sentences)\n",
        "\n",
        "    # Tokenize and pad sentences\n",
        "    en_tokenized = tokenize_sentences(en_sentences, en_vocab, 200)\n",
        "    hi_tokenized = tokenize_sentences(hi_sentences, hi_vocab, 200)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    src_data = torch.tensor(en_tokenized)\n",
        "    tgt_data = torch.tensor(hi_tokenized)\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    src_train, src_test, tgt_train, tgt_test = train_test_split(src_data, tgt_data, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    return src_train, src_test, tgt_train, tgt_test, en_vocab, hi_vocab\n",
        "\n",
        "src_train, src_test, tgt_train, tgt_test, en_vocab, hi_vocab = preprocess_and_split_data(en_sentences, hi_sentences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6OdXTK8UCad"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEE6nB39emtq",
        "outputId": "d219f7c0-4fd0-48c5-8fbe-8895fff5c182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 6.3045220375061035\n",
            "Epoch: 2, Loss: 6.299135684967041\n",
            "Epoch: 3, Loss: 6.270253658294678\n",
            "Epoch: 4, Loss: 6.259846210479736\n",
            "Epoch: 5, Loss: 6.259012699127197\n",
            "Epoch: 6, Loss: 6.2588419914245605\n",
            "Epoch: 7, Loss: 6.2587761878967285\n",
            "Epoch: 8, Loss: 6.25874137878418\n",
            "Epoch: 9, Loss: 6.2587199211120605\n",
            "Epoch: 10, Loss: 6.258707046508789\n"
          ]
        }
      ],
      "source": [
        "src_vocab_size = len(en_vocab)\n",
        "tgt_vocab_size = len(hi_vocab)\n",
        "d_model = 512\n",
        "num_heads = 8\n",
        "num_layers = 6\n",
        "d_ff = 2048\n",
        "max_seq_length = 200\n",
        "dropout = 0.1\n",
        "\n",
        "# Transformer model\n",
        "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# Training loop\n",
        "transformer.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "    optimizer.zero_grad()\n",
        "    output = transformer(src_train, tgt_train[:, :-1])\n",
        "    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_train[:, 1:].contiguous().view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gqmyX4EUFFW"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4BeteiWoW9sb"
      },
      "outputs": [],
      "source": [
        "def tensor_to_sentence(tensor, vocab, remove_pad=True):\n",
        "    sentence = []\n",
        "    for num in tensor:\n",
        "      word = list(vocab.keys())[list(vocab.values()).index(num.item())]\n",
        "      sentence.append(word)\n",
        "    if remove_pad:\n",
        "          sentence = [word for word in sentence if word != '<PAD>']\n",
        "    return \" \".join(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "L0SFqynDUN3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47b6673b-c18b-4d73-8ab1-a9ec1056f7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 6.26\n"
          ]
        }
      ],
      "source": [
        "transformer.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    val_output = transformer(src_test, tgt_test[:, :-1])\n",
        "\n",
        "    # Calculate and print validation loss\n",
        "    val_loss = criterion(val_output.contiguous().view(-1, tgt_vocab_size), tgt_test[:, 1:].contiguous().view(-1))\n",
        "    print(f\"Validation Loss: {val_loss.item():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23azJb-qXDg1"
      },
      "source": [
        "# Translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "XPjvuT9TXAzq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685f0861-5b73-4c19-fd9a-d489d8edb972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  They raised slogans against the government and the administration.\n",
            "Expected:  उन्होंने प्रशासन और सरकार के खिलाफ नारेबाजी की।\n",
            "Predicted:  उन्होंने प्रशासन और सरकार के खिलाफ नारेबाजी की।\n"
          ]
        }
      ],
      "source": [
        "input_tensor = src_test[2]\n",
        "input_sentence = tensor_to_sentence(input_tensor, en_vocab)\n",
        "print(\"Input: \", input_sentence)\n",
        "\n",
        "target_tensor = tgt_test[2]\n",
        "target_sentence = tensor_to_sentence(target_tensor, hi_vocab)\n",
        "print(\"Expected: \", target_sentence)\n",
        "\n",
        "predicted_tensor = val_output.argmax(dim=-1)\n",
        "predicted_sentence = tensor_to_sentence(predicted_tensor[0], hi_vocab)\n",
        "print(\"Predicted: \", target_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RESULTS AND DISCUSSION**\n",
        "\n",
        "A transformer-based machine translator has successfully been trained. A sample translation shows that it gives an accurate and comprehensible translation from English to Hindi.\n",
        "\n",
        "However, there were some drawbacks and limitations of this model. This includes:\n",
        "\n",
        "**1. Computational Limitations:** The Samanantar Dataset consists of millions of translation data. However, using only Google Colab computational resources, the storage quota kept being exceeded and hence, the model was trained only on the first 100 sentences.\n",
        "\n",
        "**2. Evaluation Metrics:** The validation loss estimation for this model is close to 6.3, which is an extremely high value. This is a result of the fact that we only considered a small portion of the dataset for the training of this model."
      ],
      "metadata": {
        "id": "oxBiCqCqnPlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONCLUSION**\n",
        "\n",
        "The above transformer based translation model works decently well for translations from English to Hindi, as per the Samanantar Dataset. Future enhancements can be done to decrease the validation loss and increase accuracy by utilizing GPUs."
      ],
      "metadata": {
        "id": "07hACpt0nTEo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2pTIuyzFnSd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}